## Отток клиентов банка

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

## Использованные инструменты
- python
- pandas
- matplotlib.pyplot
- scipy
- sklearn.metrics.accuracy_score
- sklearn.metrics.confusion_matrix
- sklearn.metrics.f1_score
- sklearn.metrics.precision_score
- sklearn.metrics.recall_score
- sklearn.metrics.roc_curve
- sklearn.metrics.roc_auc_score
- sklearn.model_selection.train_test_split
- sklearn.preprocessing.StandardScaler
- sklearn.linear_model.LogisticRegression
- sklearn.tree.DecisionTreeClassifier
- sklearn.ensemble.RandomForestClassifier
- sklearn.dummy.DummyClassifier
- sklearn.utils.shuffle

## Результат 

Изучив предоставленную таблицу, провели предобработку данных - привели название столбцов к аккуратному виду, заполнили пропуски. Столбцы содержащие текстовые значения преобразовали методом прямого кодирования OHE. Удалил столбцы, которые не нужны для обучения модели.

Разделили данные на три выборки - обучающую, валидационную и тестовую. Масштабировали численные признаки трёх выборок.

Провели исследование моделей машинного обучения. Так как в данных имелся сильный дисбалланс - примерно 80% отрицательных значений и 20% положительных значений, все модели показали низкие показатели точности, полноты и F1-меры, показывали большое количество ошибок.

Разобрали два варианта устранения дисбаланса - техники upsampling и downsampling. Оба варианта показали одинаковый результат - баланс классов стал иметь соотношение: "0" - 0.501043, "1" - 0.498957.

Для получения новой обучающей выборки использовали операцию upsampling - увеличили в 4 раза класс "1" в обучающей выборке.

На новой обучающей выборке наилучшие значения показала модель Случайный лес - F1-мера - 0.608, AUC-ROC - 0.8396. Поэтому для проверки на тестовой выборке выбрали эту модель.

Модель прошла проверку на тестовой выборке и прошла проверку на адекватность.

По результатам итогового тестирования выбранная модель обучения показала значения метрик:
- accuracy: 0.791
- полнота: 0.565
- точность: 0.660
- F1: 0.609
- AUC-ROC: 0.826.
Метрики качества модели F1-мера и ROC-AUC, хоть и работают по-разному и опираются на разные показатели, но между ними прослеживается связь. Чем выше метрика F1-score, тем выше значение AUC-ROC.

Исходя из этого делаем вывод, что выбранная нами модель эффективна и адекватна.