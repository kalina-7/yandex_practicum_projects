{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11dd954",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a67443",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bc32e",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f5739",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5a108",
   "metadata": {},
   "source": [
    "**Загружаем необходимые библиотеки и инструменты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5e2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198dab7",
   "metadata": {},
   "source": [
    "**Загрузим и изучим датасет**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364aa90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('D:/Яндекс Практикум/23. Машинное обучение для текстов/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55302d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fb5dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3099e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecbbc83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bc5f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53ba05c",
   "metadata": {},
   "source": [
    "Данные загружены и изучены. Дубликаты и пропуски не обнаружены. Наш целевой признак - столбец `toxic` - содержит приблизительно 10% негативных комментариев, т.е. наблюдается высокий дисбалланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a604d4",
   "metadata": {},
   "source": [
    "**Очистка текста**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1b2e1",
   "metadata": {},
   "source": [
    "Напишем функцию очистки текста и функцию лемматизации текста. Лемматизированный текст сохраним в новом столбце `processed_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903ede1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    regular = r'[^\\w ]'\n",
    "    regular_url = r'(http\\S+)|(www\\S+)|([\\w\\d]+www\\S+)|([\\w\\d]+http\\S+)'\n",
    "    text = re.sub(regular, ' ', text)\n",
    "    text = re.sub(regular_url, ' ', text)\n",
    "    text = re.sub(r'(\\d+\\s\\d+)|(\\d+)',' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "def lemmatize(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_text = [word for word in tokens if word not in stop_words]\n",
    "    tagged_tokens = nltk.pos_tag(stop_text)\n",
    "    lemmatized_tokens = []\n",
    "    for token, tag in tagged_tokens:\n",
    "        pos = get_wordnet_pos(tag)\n",
    "        lemma = lemmatizer.lemmatize(token, pos)\n",
    "        lemmatized_tokens.append(lemma)\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text\n",
    " \n",
    "data['processed_text'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d022beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits make username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  explanation edits make username hardcore metal...  \n",
       "1  aww match background colour seemingly stuck th...  \n",
       "2  hey man really try edit war guy constantly rem...  \n",
       "3  make real suggestion improvement wonder sectio...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66dcc5",
   "metadata": {},
   "source": [
    "**Разделим данные на два датасета - тренировочный и тестовый**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807ae2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data,train_size=0.75,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed7f6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119469, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a342d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39823, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff8f99",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcff00",
   "metadata": {},
   "source": [
    "**Обучим три модели - Логистическую регрессию, Дерево решений и модель градиентного бустинга LightGBM. Для этого с помощью кроссвалидации разобьём тренировочный датасет на тренировочную, валидационную и тестовую выборки, подберём гиперпараметры с помощью GridSearchCV. Получим предсказания. Оценим качество предсказаний с помощью метрик F1-мера. Затем выберем лучшую модель для испытания на тестовых данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c246f7e",
   "metadata": {},
   "source": [
    "**Модель Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6f0a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'lr__C': 5.0, 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "f1_score: 0.7792148854095756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21512\n",
      "           1       0.85      0.72      0.78      2382\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.85      0.88     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [01:04<04:18, 64.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7741935483870966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.84      0.71      0.77      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.85      0.88     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'lr__C': 5.0, 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "f1_score: 0.7840501792114696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21461\n",
      "           1       0.86      0.72      0.78      2433\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.92      0.85      0.88     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 2/5 [02:10<03:15, 65.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7774798927613941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.85      0.71      0.78      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.85      0.88     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'lr__C': 5.0, 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "f1_score: 0.7603268270540172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21480\n",
      "           1       0.84      0.69      0.76      2414\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.90      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [03:15<02:10, 65.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7693685624720108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.85      0.71      0.77      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.85      0.87     23894\n",
      "weighted avg       0.95      0.96      0.96     23894\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'lr__C': 5.0, 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "f1_score: 0.7712243074173369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     21471\n",
      "           1       0.84      0.71      0.77      2423\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.90      0.85      0.87     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [04:19<01:04, 64.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7765649365114725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.85      0.72      0.78      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.85      0.88     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'lr__C': 5.0, 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n",
      "f1_score: 0.7741793346552105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21407\n",
      "           1       0.86      0.71      0.77      2487\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.85      0.88     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [05:22<00:00, 64.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7818506928922664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.86      0.72      0.78      2433\n",
      "\n",
      "    accuracy                           0.96     23893\n",
      "   macro avg       0.91      0.85      0.88     23893\n",
      "weighted avg       0.96      0.96      0.96     23893\n",
      "\n",
      "Average f1_score: 0.773799106749522\n",
      "0.7740624285691966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = train_data['processed_text']\n",
    "y = train_data['toxic']\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "best_test_params = 0\n",
    "best_params_gs_lr = []\n",
    "\n",
    "for trainval_index, test_index in tqdm(cv.split(X, y), total=cv.get_n_splits()):\n",
    "    X_trainval, X_test = X.iloc[trainval_index], X.iloc[test_index]\n",
    "    y_trainval, y_test = y.iloc[trainval_index], y.iloc[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(use_idf=True, norm='l2', smooth_idf=True, \n",
    "                                 strip_accents=None, lowercase=False, preprocessor=None)\n",
    "    \n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "    param_grid = {'lr__penalty': ['l1', 'l2'],\n",
    "                   'lr__C': [1.0, 5.0, 10.0],\n",
    "                   'lr__solver': ['lbfgs', 'liblinear']}\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', tfidf_vect),\n",
    "        ('lr', lr)\n",
    "    ])\n",
    "\n",
    "    gs_lr_tfidf = GridSearchCV(pipeline, param_grid,\n",
    "                               scoring='f1',\n",
    "                               cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    gs_lr_tfidf.fit(X_train, y_train)\n",
    "\n",
    "    best_params = gs_lr_tfidf.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    y_pred = gs_lr_tfidf.predict(X_val)\n",
    "\n",
    "    f1_score_val = f1_score(y_val, y_pred)\n",
    "    print(\"f1_score:\", f1_score_val)\n",
    "\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "    y_pred_test = gs_lr_tfidf.predict(X_test)\n",
    "    f1_score_test = f1_score(y_test, y_pred_test)\n",
    "    print(\"Test f1_score:\", f1_score_test)\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    results.append(f1_score_val)\n",
    "\n",
    "    if f1_score_test > best_test_params:\n",
    "        best_test_params = f1_score_test\n",
    "        best_params_gs_lr = gs_lr_tfidf.best_params_\n",
    "        gs_lr_best_score_tfidf = gs_lr_tfidf.best_score_\n",
    "\n",
    "average_f1_score = np.mean(results)\n",
    "print(\"Average f1_score:\", average_f1_score)\n",
    "print(gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef6c4e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Логистическая регрессия\n",
      "F1 лучшей модели: 0.7740624285691966\n",
      "Параметры лучшей модели: {'lr__C': 5.0, 'lr__penalty': 'l1', 'lr__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Модель Логистическая регрессия\")\n",
    "print(\"F1 лучшей модели:\", gs_lr_best_score_tfidf)\n",
    "print(\"Параметры лучшей модели:\", best_params_gs_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be14217",
   "metadata": {},
   "source": [
    "**Модель Дерево решений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79566908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters: {'dt__max_depth': 76}\n",
      "f1_score: 0.7174424071462153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21512\n",
      "           1       0.82      0.64      0.72      2382\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.89      0.81      0.84     23894\n",
      "weighted avg       0.95      0.95      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [04:54<19:36, 294.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7094972067039105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21460\n",
      "           1       0.82      0.63      0.71      2434\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.89      0.81      0.84     23894\n",
      "weighted avg       0.94      0.95      0.94     23894\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters: {'dt__max_depth': 76}\n",
      "f1_score: 0.7153385536619069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21461\n",
      "           1       0.81      0.64      0.72      2433\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.89      0.81      0.84     23894\n",
      "weighted avg       0.95      0.95      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [09:53<14:50, 296.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7155756207674943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21460\n",
      "           1       0.79      0.65      0.72      2434\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.88      0.82      0.84     23894\n",
      "weighted avg       0.94      0.95      0.94     23894\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters: {'dt__max_depth': 79}\n",
      "f1_score: 0.707243693589447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21480\n",
      "           1       0.80      0.63      0.71      2414\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.88      0.81      0.84     23894\n",
      "weighted avg       0.94      0.95      0.94     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [14:59<10:02, 301.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7218799908738306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21460\n",
      "           1       0.81      0.65      0.72      2434\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.89      0.82      0.85     23894\n",
      "weighted avg       0.95      0.95      0.95     23894\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters: {'dt__max_depth': 79}\n",
      "f1_score: 0.7191216834400732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21471\n",
      "           1       0.81      0.65      0.72      2423\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.88      0.82      0.85     23894\n",
      "weighted avg       0.95      0.95      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [20:03<05:02, 302.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7237442922374429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21460\n",
      "           1       0.81      0.65      0.72      2434\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.89      0.82      0.85     23894\n",
      "weighted avg       0.95      0.95      0.95     23894\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters: {'dt__max_depth': 77}\n",
      "f1_score: 0.7102593010146562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21407\n",
      "           1       0.81      0.63      0.71      2487\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.88      0.81      0.84     23894\n",
      "weighted avg       0.94      0.95      0.94     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [25:19<00:00, 303.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7178661761324442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21460\n",
      "           1       0.81      0.64      0.72      2433\n",
      "\n",
      "    accuracy                           0.95     23893\n",
      "   macro avg       0.89      0.81      0.84     23893\n",
      "weighted avg       0.95      0.95      0.95     23893\n",
      "\n",
      "Average f1_score: 0.7138811277704598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = train_data['processed_text']\n",
    "y = train_data['toxic']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "best_test_params = 0\n",
    "best_params_gs_dt = []\n",
    "\n",
    "for trainval_index, test_index in tqdm(cv.split(X, y), total=cv.get_n_splits()):\n",
    "    X_trainval, X_test = X.iloc[trainval_index], X.iloc[test_index]\n",
    "    y_trainval, y_test = y.iloc[trainval_index], y.iloc[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(use_idf=True, norm='l2', smooth_idf=True, \n",
    "                                 strip_accents=None, lowercase=False, preprocessor=None)\n",
    "    X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf_vect.transform(X_val)\n",
    "    X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    param_grid = {'dt__max_depth' : np.arange(76, 80)}\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', tfidf_vect),\n",
    "        ('dt', dt)\n",
    "    ])\n",
    "\n",
    "    gs_dt_tfidf = GridSearchCV(pipeline, param_grid,\n",
    "                               scoring='f1',\n",
    "                               cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    gs_dt_tfidf.fit(X_train, y_train)\n",
    "\n",
    "    best_params = gs_dt_tfidf.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    y_pred = gs_dt_tfidf.predict(X_val)\n",
    "\n",
    "    f1_score_val = f1_score(y_val, y_pred)\n",
    "    print(\"f1_score:\", f1_score_val)\n",
    "\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "    y_pred_test = gs_dt_tfidf.predict(X_test)\n",
    "    f1_score_test = f1_score(y_test, y_pred_test)\n",
    "    print(\"Test f1_score:\", f1_score_test)\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    results.append(f1_score_val)\n",
    "\n",
    "    if f1_score_test > best_test_params:\n",
    "        best_test_params = f1_score_test\n",
    "        best_params_gs_dt = gs_dt_tfidf.best_params_\n",
    "        gs_dt_best_score_tfidf = gs_dt_tfidf.best_score_\n",
    "\n",
    "average_f1_score = np.mean(results)\n",
    "print(\"Average f1_score:\", average_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ede5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Дерево решений\n",
      "F1 лучшей модели: 0.7200899657452525\n",
      "Параметры лучшей модели: {'dt__max_depth': 79}\n"
     ]
    }
   ],
   "source": [
    "print(\"Модель Дерево решений\")\n",
    "print(\"F1 лучшей модели:\", gs_dt_best_score_tfidf)\n",
    "print(\"Параметры лучшей модели:\", best_params_gs_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14f3b6",
   "metadata": {},
   "source": [
    "**Модель градиентного бустинга LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283fe7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters: {'lg__learning_rate': 0.1, 'lg__num_leaves': 91}\n",
      "f1_score: 0.7594762232942798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21512\n",
      "           1       0.84      0.69      0.76      2382\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.90      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [10:46<43:07, 646.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7579042457091237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.84      0.69      0.76      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.90      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters: {'lg__learning_rate': 0.1, 'lg__num_leaves': 71}\n",
      "f1_score: 0.7572727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21461\n",
      "           1       0.85      0.68      0.76      2433\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [21:47<32:45, 655.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7694394213381553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.86      0.70      0.77      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.84      0.87     23894\n",
      "weighted avg       0.96      0.96      0.96     23894\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters: {'lg__learning_rate': 0.1, 'lg__num_leaves': 91}\n",
      "f1_score: 0.7481851179673321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     21480\n",
      "           1       0.83      0.68      0.75      2414\n",
      "\n",
      "    accuracy                           0.95     23894\n",
      "   macro avg       0.90      0.83      0.86     23894\n",
      "weighted avg       0.95      0.95      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [33:05<22:11, 665.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7602523659305993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.84      0.69      0.76      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.90      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters: {'lg__learning_rate': 0.1, 'lg__num_leaves': 81}\n",
      "f1_score: 0.7644144144144144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21471\n",
      "           1       0.84      0.70      0.76      2423\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.90      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [43:33<10:50, 650.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7606527651858568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     21460\n",
      "           1       0.85      0.69      0.76      2434\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters: {'lg__learning_rate': 0.1, 'lg__num_leaves': 71}\n",
      "f1_score: 0.7605884975479268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     21407\n",
      "           1       0.85      0.69      0.76      2487\n",
      "\n",
      "    accuracy                           0.96     23894\n",
      "   macro avg       0.91      0.84      0.87     23894\n",
      "weighted avg       0.95      0.96      0.95     23894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [54:03<00:00, 648.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.7559161595672751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     21460\n",
      "           1       0.84      0.69      0.76      2433\n",
      "\n",
      "    accuracy                           0.95     23893\n",
      "   macro avg       0.90      0.84      0.87     23893\n",
      "weighted avg       0.95      0.95      0.95     23893\n",
      "\n",
      "Average f1_score: 0.7579873960993361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = train_data['processed_text']\n",
    "y = train_data['toxic']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "best_test_params = 0\n",
    "best_params_gs_lgb = []\n",
    "\n",
    "for trainval_index, test_index in tqdm(cv.split(X, y), total=cv.get_n_splits()):\n",
    "    X_trainval, X_test = X.iloc[trainval_index], X.iloc[test_index]\n",
    "    y_trainval, y_test = y.iloc[trainval_index], y.iloc[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(use_idf=True, norm='l2', smooth_idf=True, \n",
    "                                 strip_accents=None, lowercase=False, preprocessor=None)\n",
    "    X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf_vect.transform(X_val)\n",
    "    X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    lgb_estimator = lgb.LGBMClassifier(task='train', boosting_type='gbdt', objective='regression', verbose=-1)\n",
    "\n",
    "    param_grid_lgb = {'lg__num_leaves': [71, 81, 91],\n",
    "                      'lg__learning_rate': [0.01, 0.1, 1.0]}\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', tfidf_vect),\n",
    "        ('lg', lgb_estimator)\n",
    "    ])\n",
    "\n",
    "    gs_lgb_tfidf = GridSearchCV(pipeline, \n",
    "                               param_grid_lgb,\n",
    "                               scoring='f1',\n",
    "                               cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=-1,\n",
    "                               error_score='raise')\n",
    "\n",
    "    gs_lgb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "    best_params = gs_lgb_tfidf.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    y_pred = gs_lgb_tfidf.predict(X_val)\n",
    "\n",
    "    f1_score_val = f1_score(y_val, y_pred)\n",
    "    print(\"f1_score:\", f1_score_val)\n",
    "\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "    y_pred_test = gs_lgb_tfidf.predict(X_test)\n",
    "    f1_score_test = f1_score(y_test, y_pred_test)\n",
    "    print(\"Test f1_score:\", f1_score_test)\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    results.append(f1_score_val)\n",
    "\n",
    "    if f1_score_test > best_test_params:\n",
    "        best_test_params = f1_score_test\n",
    "        best_params_gs_lgb = gs_lgb_tfidf.best_params_\n",
    "        gs_lgb_best_score_tfidf = gs_lgb_tfidf.best_score_\n",
    "\n",
    "average_f1_score = np.mean(results)\n",
    "print(\"Average f1_score:\", average_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1434081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель градиентного бустинга LightGBM\n",
      "F1 лучшей модели: 0.7540526744791002\n",
      "Параметры лучшей модели: {'lg__learning_rate': 0.1, 'lg__num_leaves': 71}\n"
     ]
    }
   ],
   "source": [
    "print(\"Модель градиентного бустинга LightGBM\")\n",
    "print(\"F1 лучшей модели:\", gs_lgb_best_score_tfidf)\n",
    "print(\"Параметры лучшей модели:\", best_params_gs_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb680f",
   "metadata": {},
   "source": [
    "Лучшие показатели - метрику качества F1 - 0.77 и время обучения - 5 мин. 22 сек. показала модель Логистическая регрессия. Выбираем её для тестирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc2702",
   "metadata": {},
   "source": [
    "**Выделим из тестового датафрейма целевой и обучающий признаки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecbf903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data['processed_text']\n",
    "y_test = test_data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52acfbbb",
   "metadata": {},
   "source": [
    "**TF-IDF-векторизация полного тренировочного и тестового датафреймов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37190cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_vect.fit_transform(X)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092de66",
   "metadata": {},
   "source": [
    "**Обучим модель Логистическая регрессия с подобранными гиперпараметрами и получим предсказание на тестовых данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3103f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 на тестовых данных: 0.7903334683407588\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(penalty='l1', C=5.0, solver='liblinear').fit(X_tfidf, y)\n",
    "predicts = best_model.predict(X_test_tfidf)\n",
    "print(\"Метрика F1 на тестовых данных:\", f1_score(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1df26",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6ca19",
   "metadata": {},
   "source": [
    "**Нам была поставлена задача - обучить модель классифицировать комментарии на позитивные и негативные. Для её достижения нами были поставлены и выполнены следующие задачи:**\n",
    "- загружены необходимые библиотеки и инструменты;\n",
    "- загружен и изучеен предоставленный датафрейм;\n",
    "- произведена обработка и подготовка данных для обучения моделей: \n",
    "    - проверка на дубликаты, \n",
    "    - очистка текста от лишних символов,\n",
    "    - лемматизация текста,\n",
    "    - разделение данных на тренировочный и тестовый датасеты;\n",
    "- были выбраны три модели для обучения - Логистическая регрессия, Дерево решений и модель градиентного бустинга LightGBM;\n",
    "- произвели обучение моделей с подбором гиперпараметров;\n",
    "- для тестирования выбрали лучшую модель по метрике F1 - Логистическая регрессия;\n",
    "- получили предсказание модели на тестовом датафрейме.\n",
    "\n",
    "**Во время подготовки данных для обучения выполнили очистку и лемматизацию текста, полученный текст сохранили в новом столбце `processed_text`, разбили исходный датасет на два - тренировочный и тестовый.**\n",
    "\n",
    "**Для обучения были выбраны три модели - Логистическая регрессия, Дерево решений и модель градиентного бустинга LightGBM. Для обучения каждой модели с помощью кроссвалидации разбили тренировочный датасет на тренировочную, валидационную и тестовую выборки, подобрали гиперпараметры с помощью GridSearchCV и получили предсказания. Лучшую метрику F1 - 0.77 и минимальное время обучения - 5 мин. 22 сек. показала модель Логистическая регрессия. Поэтому для тестирования была выбрана эта модель.**\n",
    "\n",
    "**По результатам проверки модели на тестовых данных убедились, что модель является работоспособной и надёжной, имеет высокую  F1-меру - 0.79, при минимально допустимом значении 0.75 и может применяться для классифицикации комментариев пользователей на позитивные и негативные.**\n",
    "\n",
    "**Поставленная задача выполнена.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
