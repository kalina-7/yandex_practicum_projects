## Проект для «Викишоп»

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Нужно обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

Необходимо построить модель со значением метрики качества *F1* не меньше 0.75. 

## Описание данных

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## Использованные инструменты
- python
- numpy
- pandas
- lightgbm
- nltk
- nltk.corpus.stopwords
- nltk.corpus.wordnet
- nltk.stem.WordNetLemmatizer
- nltk.tokenize.word_tokenize
- re
- sklearn.feature_extraction.text.TfidfVectorizer
- sklearn.linear_model.LogisticRegression
- sklearn.metrics.f1_score
- sklearn.metrics.classification_report
- sklearn.model_selection.GridSearchCV
- sklearn.model_selection.StratifiedKFold
- sklearn.model_selection.train_test_split
- sklearn.pipeline.Pipeline
- sklearn.tree.DecisionTreeClassifier
- tqdm

## Результат

Нам была поставлена задача - обучить модель классифицировать комментарии на позитивные и негативные. Для её достижения нами были поставлены и выполнены следующие задачи:
- загружены необходимые библиотеки и инструменты;
- загружен и изучеен предоставленный датафрейм;
- произведена обработка и подготовка данных для обучения моделей: 
    - проверка на дубликаты, 
    - очистка текста от лишних символов,
    - лемматизация текста,
    - разделение данных на тренировочный и тестовый датасеты;
- были выбраны три модели для обучения - Логистическая регрессия, Дерево решений и модель градиентного бустинга LightGBM;
- произвели обучение моделей с подбором гиперпараметров;
- для тестирования выбрали лучшую модель по метрике F1 - Логистическая регрессия;
- получили предсказание модели на тестовом датафрейме.

Во время подготовки данных для обучения выполнили очистку и лемматизацию текста, полученный текст сохранили в новом столбце `processed_text`, разбили исходный датасет на два - тренировочный и тестовый.

Для обучения были выбраны три модели - Логистическая регрессия, Дерево решений и модель градиентного бустинга LightGBM. Для обучения каждой модели с помощью кроссвалидации разбили тренировочный датасет на тренировочную, валидационную и тестовую выборки, подобрали гиперпараметры с помощью GridSearchCV и получили предсказания. Лучшую метрику F1 - 0.77 и минимальное время обучения - 5 мин.22 сек. показала модель Логистическая регрессия. Поэтому для тестирования была выбрана эта модель.

По результатам проверки модели на тестовых данных убедились, что модель является работоспособной и надёжной, имеет высокую  F1-меру - 0.79, при минимально допустимом значении 0.75 и может применяться для классифицикации комментариев пользователей на позитивные и негативные.

Поставленная задача выполнена.